#dev.off()
tiff("SanJVern_Date_Discharge_NO3_conc_no_log2.tif",height = 700, width = 1000, res=120)
plotConcQSmooth(eList,date1, date2, date3,date4, date5, date6, qLow, qHigh, logScale=FALSE,printLegend =TRUE,legendLeft=0,legendTop=0,printTitle=TRUE)
dev.off()
#tiff("SanJVern_Date_Discharge_NO3_conc_no_log1.tif",height = 700, width = 1000, res=120)
#plotConcQSmooth(eList,date1, date2, date3, qLow, qHigh, logScale=FALSE,printLegend =TRUE,legendLeft=0,legendTop=0,printTitle=TRUE)
#dev.off()
tiff("SanJVern_Date_Discharge_NO3_conc_no_log2.tif",height = 700, width = 1000, res=120)
plotConcQSmooth(eList,date4, date5, date6, qLow, qHigh, logScale=FALSE,printLegend =TRUE,legendLeft=0,legendTop=0,printTitle=TRUE)
dev.off()
plotConcQSmooth(eList,date4, date5, date6, qLow, qHigh, logScale=FALSE,printLegend =TRUE,legendLeft=0,legendTop=0)#printTitle=TRUE)
plotConcQSmooth(eList,date4, date5, date6, qLow, qHigh, logScale=FALSE,printLegend =FALSE,legendLeft=0,legendTop=0)#printTitle=TRUE)
#tiff("SanJVern_Date_Discharge_NO3_conc_no_log_first30years.tif",height = 700, width = 1000, res=120)
plotConcQSmooth(eList,date1, date2, date3, qLow, qHigh, logScale=FALSE,printLegend =TRUE,legendLeft=0,legendTop=0,printTitle=TRUE)
dev.off()
tiff("SanJVern_Date_Discharge_NO3_conc_no_log_last30years.tif",height = 700, width = 1000, res=120)
plotConcQSmooth(eList,date4, date5, date6, qLow, qHigh, logScale=FALSE,printLegend =TRUE,legendLeft=0,legendTop=0, printTitle=TRUE)
#################  Using the plotConcQSmooth function
###########
#First do flow duration analysis
flowDuration(eList, centerDate = "06-01", qUnit = 2, span = 30)
date1 <- "1972-06-01"
date2 <- "1982-06-01"
date3 <- "1992-06-01"
date4 <- "2000-06-01"
date5 <- "2009-06-01"
date6 <- "2019-06-01"
qLow= baseQ
qHigh=highQ7
#tiff("SanJVern_Date_Discharge_NO3_conc_no_log_first30years.tif",height = 700, width = 1000, res=120)
plotConcQSmooth(eList,date1, date2, date3, qLow, qHigh, logScale=FALSE,printLegend =TRUE,legendLeft=0,legendTop=0,printTitle=TRUE)
dev.off()
tiff("SanJVern_Date_Discharge_NO3_conc_no_log_last30years.tif",height = 700, width = 1000, res=120)
plotConcQSmooth(eList,date4, date5, date6, qLow, qHigh, logScale=FALSE,printLegend =TRUE,legendLeft=0,legendTop=0, printTitle=TRUE)
dev.off()
#tiff("SanJVern_Date_Discharge_NO3_conc_no_log_1st.tif",height = 700, width = 1000, res=120)
plotConcQSmooth(eList,date1, date2, date3, qLow, qHigh, logScale=FALSE,printLegend =TRUE,legendLeft=0,legendTop=0,printTitle=TRUE)
dev.off()
###This is a script taken from another study, but we will do the same thing for the PES project
##So, the script needs to be modifed for the Vernalis site
# Load required libraries
library(EGRET)
library(dataRetrieval)
library(rloadest)
library(EGRETci)
library(foreach)
library(doParallel)
library(iterators)
library(zoo)
library(plotrix)
library(lubridate)
library(changepoint)
library(corrplot)
library(RColorBrewer)
library(plotly)
library(ggplot2)
library(viridis)
library(fields)
library(extrafont)
loadfonts()
################  Using the plotConcQSmooth function
###########
#First do flow duration analysis
flowDuration(eList, centerDate = "06-01", qUnit = 2, span = 30)
date1 <- "1972-06-01"
date2 <- "1982-06-01"
date3 <- "1992-06-01"
date4 <- "2000-06-01"
date5 <- "2009-06-01"
date6 <- "2019-06-01"
qLow= baseQ
qHigh=highQ7
#tiff("SanJVern_Date_Discharge_NO3_conc_no_log_1st.tif",height = 700, width = 1000, res=120)
plotConcQSmooth(eList,date1, date2, date3, qLow, qHigh, logScale=FALSE,printLegend =TRUE,legendLeft=0,legendTop=0,printTitle=TRUE)
dev.off()
tiff("SanJVern_Date_Discharge_NO3_conc_no_log_last30years.tif",height = 700, width = 1000, res=120)
plotConcQSmooth(eList,date4, date5, date6, qLow, qHigh, logScale=FALSE,printLegend =TRUE,legendLeft=0,legendTop=0, printTitle=TRUE)
dev.off()
#tiff("SanJVern_Date_Discharge_NO3_conc_no_log1st.tif",height = 700, width = 1000, res=120)
plotConcQSmooth(eList,date1, date2, date3, qLow, qHigh, logScale=FALSE,printLegend =TRUE,legendLeft=0,legendTop=0,printTitle=TRUE)
###This is a script taken from another study, but we will do the same thing for the PES project
##So, the script needs to be modifed for the Vernalis site
# Load required libraries
library(EGRET)
library(dataRetrieval)
library(rloadest)
library(EGRETci)
library(foreach)
library(doParallel)
library(iterators)
library(zoo)
library(plotrix)
library(lubridate)
library(changepoint)
library(corrplot)
library(RColorBrewer)
library(plotly)
library(ggplot2)
library(viridis)
library(fields)
library(extrafont)
loadfonts()
parameterCd <- "00671"
startDate <- "1971-10-01"
endDate <- "2019-06-01"
Daily <- readNWISDaily(siteNumber, QParameterCd, startDate, endDate)
fileName <- "UT5_OP.csv"
Sample <- readUserSample(filePath, fileName)
parameterCd <- "00671"
startDate <- "1971-10-01"
endDate <- "2019-06-01"
Daily <- readNWISDaily(siteNumber, QParameterCd, startDate, endDate)
filePath <- "C:/Users/dsaleh/Documents/GitHub/PES_Project/Vernalis_EGRET/"
Daily <- readNWISDaily(siteNumber, QParameterCd, startDate, endDate)
Sample <- readNWISSample(siteNumber, parameterCd, startDate, endDate)
##NWIS DIN data has a gap between 1974 and 1979.  We will need to supplement
##the missing time using Charlie Kratzer's data
write.csv(Sample,"NWIS_OP.csv")
startDate <- "1980-10-01"
endDate <- "2019-06-01"
Daily <- readNWISDaily(siteNumber, QParameterCd, startDate, endDate)
filePath <- "C:/Users/dsaleh/Documents/GitHub/PES_Project/Vernalis_EGRET/"
Daily <- readNWISDaily(siteNumber, QParameterCd, startDate, endDate)
Sample <- readNWISSample(siteNumber, parameterCd, startDate, endDate)
##NWIS DIN data has a gap between 1974 and 1979.  We will need to supplement
##the missing time using Charlie Kratzer's data
write.csv(Sample,"NWIS_OP.csv")
INFO <- readNWISInfo(siteNumber = siteNumber, parameterCd = parameterCd, interactive=FALSE)
INFO$staAbbrev <- paste(strsplit(INFO$station_nm," ")[[1]][1],strsplit(INFO$station_nm," ")[[1]][2])
eList <- NULL
eList <- mergeReport(INFO, Daily, Sample)
# Change the working directory; redirect plot output to OP folder
setwd("C:/Users/dsaleh/Documents/GitHub/PES_Project/Vernalis_EGRET/")
subDir <- 'C:/Users/dsaleh/Documents/GitHub/PES_Project/Vernalis_EGRET/OP/EGRET_plots'
# Change the working directory; redirect plot output to OP folder
setwd("C:/Users/dsaleh/Documents/GitHub/PES_Project/Vernalis_EGRET/OP")
subDir <- 'C:/Users/dsaleh/Documents/GitHub/PES_Project/Vernalis_EGRET/OP/EGRET_plots'
# Change the working directory; redirect plot output to OP folder
setwd<-("C:/Users/dsaleh/Documents/GitHub/PES_Project/Vernalis_EGRET/OP")
subDir <- ("C:/Users/dsaleh/Documents/GitHub/PES_Project/Vernalis_EGRET/OP/EGRET_plots")
# Change the working directory; redirect plot output to OP folder
setwd <-"C:/Users/dsaleh/Documents/GitHub/PES_Project/Vernalis_EGRET/OP"
subDir <- "C:/Users/dsaleh/Documents/GitHub/PES_Project/Vernalis_EGRET/OP/EGRET_plots"
######
# Change the working directory; redirect plot output to OP folder
setwd("..")
subDir <- 'OP/EGRET_plots'
if (file.exists(subDir)){
setwd(file.path(getwd(),subDir))
} else {
dir.create(file.path(getwd(),subDir), recursive = TRUE)
setwd(file.path(getwd(),subDir))
}
plotConcTimeDaily(eList)
# Plot water quality data
tiff("Conc_vs_Time_Ortho_P.tif", height = 600, width = 800, res=120)
plotConcTime(eList)
dev.off()
# Now, a classic Q-C plot
tiff("Conc-Q_UpperTruckee_-UT5_Ortho_P.tif", height = 600, width = 800, res=120)
plotConcQ(eList, logScale=TRUE)
dev.off()
# The data set as flux values rather than as concentrations
tiff("Flux-Q_SanJVernalis_Ortho_P.tif", height = 600, width = 800, res=120)
plotFluxQ(eList, fluxUnit=4)
dev.off()
plotConcTime(eList)
# Monthly boxplots
tiff("Monthly-Conc_BoxPlots_SanJVernalis_Ortho_P.tif", height = 600, width = 800, res=120)
boxConcMonth(eList, logScale=TRUE)
dev.off()
# Flow on days sampled vs. all other days
tiff("Flow_on_days_sampled_vs_all_other_days_SanJVernalis_Ortho_P.tif", height = 600, width = 800, res=120)
boxQTwice(eList, qUnit=1)
dev.off()
# Build the regression model
eList <- modelEstimation(eList, windowY = 7, windowQ = 2, windowS = 0.5, minNumObs = 100, minNumUncen = 50)
eList_OP <- eList
MonthlyResults <- calculateMonthlyResults(eList)
# Dump OP-related flow-normalized data to text file for bringing together with other monitoring sites
paLong <- 12
paStart <- 10
localDaily <- getDaily(eList_OP)
localAnnualResults <- setupYears(paStart = paStart, paLong = paLong, localDaily = localDaily)
write.table(localAnnualResults, file = 'UT5_OP_RawVals.txt', quote=FALSE, row.names=FALSE)
#####################################################
# Now start the Flow-Normalized Analysis for Ortho P
#####################################################
# Build the regression model
eList <- modelEstimation(eList, windowY = 7, windowQ = 2, windowS = 0.5, minNumObs = 100, minNumUncen = 50)
eList_OP <- eList
MonthlyResults <- calculateMonthlyResults(eList)
# Dump OP-related flow-normalized data to text file for bringing together with other monitoring sites
paLong <- 12
paStart <- 10
localDaily <- getDaily(eList_OP)
localAnnualResults <- setupYears(paStart = paStart, paLong = paLong, localDaily = localDaily)
write.table(localAnnualResults, file = 'UT5_OP_RawVals.txt', quote=FALSE, row.names=FALSE)
# Plot the annual average concentration and annual flow-normalized concentration
tiff("Ann_Avg_Conc_&_Ann_Flow_Normalized_Conc_UpperTruckee_SupTruckUT5_OP.tif", height = 600, width = 800, res=120)
plotConcHist(eList, plotFlowNorm=TRUE,cex.axis = 0.8)
dev.off()
# Plot the annual flux and annual flow-normalized flux
tiff("Ann_Flux_&_Ann_Flow_Normalized_Flux_UPperTruckee_SupTruckUT5_OP.tif", height = 600, width = 800, res=120)
plotFluxHist(eList, plotFlowNorm = TRUE) # fluxMax) # fluxMax
dev.off()
parameterCd <- "00671"
startDate <- "1980-10-01"
endDate <- "2019-06-01"
Daily <- readNWISDaily(siteNumber, QParameterCd, startDate, endDate)
filePath <- "C:/Users/dsaleh/Documents/GitHub/PES_Project/Vernalis_EGRET/"
Daily <- readNWISDaily(siteNumber, QParameterCd, startDate, endDate)
Sample <- readNWISSample(siteNumber, parameterCd, startDate, endDate)
##NWIS DIN data has a gap between 1974 and 1979.  We will need to supplement
##the missing time using Charlie Kratzer's data
write.csv(Sample,"NWIS_OP.csv")
##Add Kratzer's data to NWIS_nitrate2.csv
fileName <- "CK_OP_data.csv"
Sample <- readUserSample(filePath, fileName)
removeDuplicates(Sample)
#Sample <- readNWISSample(siteNumber, parameterCd, startDate, endDate)
INFO <- readNWISInfo(siteNumber = siteNumber, parameterCd = parameterCd, interactive=FALSE)
INFO$staAbbrev <- paste(strsplit(INFO$station_nm," ")[[1]][1],strsplit(INFO$station_nm," ")[[1]][2])
# Have a look at the available range of NO3 data
range(Sample$Date)
eList <- mergeReport(INFO, Daily, Sample)
eList <- NULL
eList <- mergeReport(INFO, Daily, Sample)
######
# Change the working directory; redirect plot output to OP folder
setwd("..")
subDir <- 'OP/EGRET_plots'
parameterCd <- "00671"
startDate <- "1980-10-01"
endDate <- "2019-06-01"
Daily <- readNWISDaily(siteNumber, QParameterCd, startDate, endDate)
filePath <- "C:/Users/dsaleh/Documents/GitHub/PES_Project/Vernalis_EGRET/"
Daily <- readNWISDaily(siteNumber, QParameterCd, startDate, endDate)
Sample <- readNWISSample(siteNumber, parameterCd, startDate, endDate)
##NWIS DIN data has a gap between 1974 and 1979.  We will need to supplement
##the missing time using Charlie Kratzer's data
write.csv(Sample,"NWIS_OP.csv")
##Add Kratzer's data to NWIS_nitrate2.csv
fileName <- "CK_OP_data.csv"
Sample <- readUserSample(filePath, fileName)
removeDuplicates(Sample)
#Sample <- readNWISSample(siteNumber, parameterCd, startDate, endDate)
INFO <- readNWISInfo(siteNumber = siteNumber, parameterCd = parameterCd, interactive=FALSE)
# Have a look at the available range of NO3 data
range(Sample$Date)
eList <- NULL
eList <- mergeReport(INFO, Daily, Sample)
######
# Change the working directory; redirect plot output to OP folder
setwd("..")
subDir <- 'OP/EGRET_plots'
if (file.exists(subDir)){
setwd(file.path(getwd(),subDir))
} else {
dir.create(file.path(getwd(),subDir), recursive = TRUE)
setwd(file.path(getwd(),subDir))
}
plotConcTimeDaily(eList)
# Plot water quality data
tiff("Conc_vs_Time_Ortho_P.tif", height = 600, width = 800, res=120)
plotConcTime(eList)
dev.off()
# Now, a classic Q-C plot
tiff("Conc-Q_UpperTruckee_-UT5_Ortho_P.tif", height = 600, width = 800, res=120)
plotConcQ(eList, logScale=TRUE)
dev.off()
# The data set as flux values rather than as concentrations
tiff("Flux-Q_SanJVernalis_Ortho_P.tif", height = 600, width = 800, res=120)
plotFluxQ(eList, fluxUnit=4)
dev.off()
plotConcTime(eList)
# Monthly boxplots
tiff("Monthly-Conc_BoxPlots_SanJVernalis_Ortho_P.tif", height = 600, width = 800, res=120)
boxConcMonth(eList, logScale=TRUE)
dev.off()
# Flow on days sampled vs. all other days
tiff("Flow_on_days_sampled_vs_all_other_days_SanJVernalis_Ortho_P.tif", height = 600, width = 800, res=120)
boxQTwice(eList, qUnit=1)
dev.off()
#####################################################
# Now start the Flow-Normalized Analysis for Ortho P
#####################################################
# Build the regression model
eList <- modelEstimation(eList, windowY = 7, windowQ = 2, windowS = 0.5, minNumObs = 100, minNumUncen = 50)
eList_OP <- eList
MonthlyResults <- calculateMonthlyResults(eList)
# Dump OP-related flow-normalized data to text file for bringing together with other monitoring sites
paLong <- 12
paStart <- 10
localDaily <- getDaily(eList_OP)
localAnnualResults <- setupYears(paStart = paStart, paLong = paLong, localDaily = localDaily)
write.table(localAnnualResults, file = 'UT5_OP_RawVals.txt', quote=FALSE, row.names=FALSE)
# Plot the annual average concentration and annual flow-normalized concentration
tiff("Ann_Avg_Conc_&_Ann_Flow_Normalized_Conc_UpperTruckee_SupTruckUT5_OP.tif", height = 600, width = 800, res=120)
plotConcHist(eList, plotFlowNorm=TRUE,cex.axis = 0.8)
dev.off()
# Plot the annual flux and annual flow-normalized flux
tiff("Ann_Flux_&_Ann_Flow_Normalized_Flux_UPperTruckee_SupTruckUT5_OP.tif", height = 600, width = 800, res=120)
plotFluxHist(eList, plotFlowNorm = TRUE) # fluxMax) # fluxMax
dev.off()
###################
# Determine which flow rates to use for discharge-specific trends
# Baseflow: mean of the annual 30-day low flows
baseQ <- mean(aggregate(Q30 ~ waterYear, data = localDaily, min)[,2])
baseQ_txt <- format(baseQ, digits=2)
baseQ_txt_cfs <- format(baseQ * 35.315, digits=2)
# mid-range: median flow rate across all years
medQ <- median(localDaily$Q)
medQ_txt <- format(medQ, digits=2)
medQ_txt_cfs <- format(medQ * 35.315, digits=2)
# high flow: get the 25% quantile of each year's maximum Q7
# This will help ensure (but not guarantee) that every year is well represented in the high-end flows
highQ7 <- as.numeric(quantile(aggregate(Q7 ~ waterYear, data = localDaily, max)[,2])[2])
highQ7_txt <- format(highQ7, digits=2)
highQ7_txt_cfs <- format(highQ7 * 35.315, digits=2)
# The following bit of script generates a figure discussed by Joe in an email on 6/2/17
# -------------------------------------------------------------------------------------
tiff("Discharge_specific_trends_OP_centered_on_06-01.tif", height = 600, width = 1200, res=120)
par(mar=c(4,6,4.1,8))
plotConcTimeSmooth(eList, q1 = baseQ, q2 = medQ, q3 = highQ7, centerDate='06-01',
yearStart=localDaily$waterYear[1], yearEnd=localDaily$waterYear[nrow(localDaily)],
logScale=TRUE, printLegend=FALSE)
# Determine y position of the legend
# ----------------------------------
y_l <- par('usr')[3]
y_u <- par('usr')[4]
y_m <- mean(y_l, y_u)
# Use the top version of the legend to add cfs
# legend('bottomleft', c(eval(substitute(expression(paste('Baseflow [',baseQ_txt,' ', m^3~s^-1,'(',baseQ_txt_cfs,' ',ft^3~s^-1,')]',sep=' ')), list(baseQ_txt=baseQ_txt, baseQ_txt_cfs=baseQ_txt_cfs))),
#                        eval(substitute(expression(paste('Median Flow [',medQ_txt,' ', m^3~s^-1,'(',medQ_txt_cfs,' ',ft^3~s^-1,')]',sep=' ')), list(medQ_txt=medQ_txt, medQ_txt_cfs=medQ_txt_cfs))),
#                        eval(substitute(expression(paste('High Flow [',highQ7_txt,' ', m^3~s^-1,'(',highQ7_txt_cfs,' ',ft^3~s^-1,')]',sep=' ')), list(highQ7_txt=highQ7_txt, highQ7_txt_cfs=highQ7_txt_cfs)))),
#                        col=c('black','red','green'), lwd=2, bg='white', bty='n')
legend('bottomleft', c(eval(substitute(expression(paste('Baseflow (',baseQ_txt,' ', m^3~s^-1,')',sep=' ')), list(baseQ_txt=baseQ_txt))),
eval(substitute(expression(paste('Median Flow (',medQ_txt,' ', m^3~s^-1,')',sep=' ')), list(medQ_txt=medQ_txt))),
eval(substitute(expression(paste('High Flow (',highQ7_txt,' ', m^3~s^-1,')',sep=' ')), list(highQ7_txt=highQ7_txt)))),
col=c('black','red','green'), lwd=2, bg='white', bty='n')
dev.off()
# Restore original plotting margins
par(mar=c(5.1,6.1,4.1,2.1))
# The following bit of script generates a figure discussed by Michael in an email on 6/2/17
# -----------------------------------------------------------------------------------------
# Get the row number corresponding to the maximum concentration for each year (bearing in mind that these are 'within group' row numbers)
out <- aggregate(ConcDay ~ waterYear, data = localDaily, which.max)
# Ensure data is ordered by water year
out <- out[ order(out$waterYear), ]
# Get a count of the number of days within each of the water years
tbl <- table(localDaily$waterYear)
# Return the absolute row positions for each water year's max concentration
out$AbsConcDay <- out$ConcDay + cumsum(c(0,tbl[-length(tbl)]))
# Make a data.frame containing only the rows with each water year's max conc
out2 <- localDaily[out$AbsConcDay,]
# Gather only the needed data
out2 <- data.frame(Date=out2$Date, Q=out2$Q, Conc=out2$ConcDay, wyr=out2$waterYear, Julian=yday(as.Date(out2$Date)))
# Need to readjust the Julian day to start on Oct 1 (This function doesn't yet account for leap years)
out2$JulianWYR <- ifelse(out2$Julian > 273, out2$Julian - 273, 92 + out2$Julian)
# Plot it
tiff("JulianDay_of_Max_OP_Conc.tif", height = 600, width = 800, res=120)
plot(out2$wyr, out2$JulianWYR, pch=16, xlab='Water Year', ylab='Julian Day', yaxs='i', ylim=c(0,370), las=1)
dev.off()
# In a follow-up email from Michael on 6/7/17, Michael suggested two alterations:
#  1) Apply a 30-day moving average
#  2) Use the flow-normalized concentration
# To start with, I'll attempt to apply a 30-day window to the simulated daily concentrations
localDaily$ConcDay_30day <- c(rep(rollapply(localDaily$ConcDay, width=30, mean)[1],times=14) , rollapply(localDaily$ConcDay, width=30, mean), rep(rollapply(localDaily$ConcDay, width=30, mean)[length(rollapply(localDaily$ConcDay, width=30, mean))], times=15))
out_m <- aggregate(ConcDay_30day ~ waterYear, data = localDaily, which.max)
out_m <- out_m[ order(out_m$waterYear), ]
out_m$AbsConcDay <- out_m$ConcDay + cumsum(c(0,tbl[-length(tbl)]))
out_m2 <- localDaily[out_m$AbsConcDay,]
out_m2 <- data.frame(Date=out_m2$Date, Q=out_m2$Q, Conc30=out_m2$ConcDay_30day, wyr=out_m2$waterYear, Julian=yday(as.Date(out_m2$Date)))
out_m2$JulianWYR <- ifelse(out_m2$Julian > 273, out_m2$Julian - 273, 92 + out_m2$Julian)
tiff("JulianDay_of_Max_OP_Conc_Using_30_rollingAvg.tif", height = 600, width = 800, res=120)
plot(out_m2$wyr, out_m2$JulianWYR, pch=16, xlab='Water Year', ylab='Julian Day', yaxs='i', ylim=c(0,370), las=1)
dev.off()
# Next, I'll try using the flow-normalized concentration (same general code flow as above)
# First, try plotting flow-normalized concentration:
# Plot it
tiff("Flow_Normalized_Conc_UT5_OP.tif", height = 600, width = 800, res=120)
plot(as.Date(localDaily$Date), localDaily$FNConc, typ='l', las=1, xlab='Time', ylab='Flow-normalized Concentration')
dev.off()
out_FN <- aggregate(FNConc ~ waterYear, data = localDaily, which.max)
out_FN <- out_FN[ order(out_FN$waterYear), ]
out_FN$AbsConcDay <- out_FN$FNConc + cumsum(c(0,tbl[-length(tbl)]))
out2_FN <- localDaily[out_FN$AbsConcDay,]
out2_FN <- data.frame(Date=out2_FN$Date, Q=out2_FN$Q, Conc=out2_FN$FNConc, wyr=out2_FN$waterYear, Julian=yday(as.Date(out2_FN$Date)))
out2_FN$JulianWYR <- ifelse(out2_FN$Julian > 273, out2_FN$Julian - 273, 92 + out2_FN$Julian)
# Plot it
tiff("JulianDay_of_Max_OP_Flow_Normalized_Conc.tif", height = 600, width = 800, res=120)
plot(out2_FN$wyr, out2_FN$JulianWYR, pch=16, xlab='Water Year', ylab='Julian Day', yaxs='i', ylim=c(0,370), las=1)
dev.off()
# --------------------------------------------------------------------------------------------------------
# The following script is for a non-standard EGRET plot and instead help generate a plot Michael requested
localDaily <- getDaily(eList)
# Will need to adjust the date range below based on each gages unique start/stop dates
early_decade <- subset(localDaily, localDaily$Date > as.Date('1990-09-30') & localDaily$Date < as.Date('2000-10-01'))
recent_decade <- subset(localDaily, localDaily$Date > as.Date('2001-09-30'))
early_decade_monthly_mn <- aggregate(ConcDay ~ MonthSeq, data = early_decade, 'mean')
recent_decade_monthly_mn <- aggregate(ConcDay ~ MonthSeq, data = recent_decade, 'mean')
# early_decade_monthly_mn$month <- format(seq(as.Date('1972-10-01'), as.Date('1982-09-30'), by='month'), '%b')
early_decade_monthly_mn$month <- rep(c(10:12,1:9), times=10)
early_decade_mon_mn <- aggregate(ConcDay ~ month, data = early_decade_monthly_mn, 'mean')
early_decade_mon_sd <- aggregate(ConcDay ~ month, data = early_decade_monthly_mn, 'sd')
early_decade_mon_mn <- early_decade_mon_mn[c(10:12,1:9),]
early_decade_mon_sd <- early_decade_mon_sd[c(10:12,1:9),]
recent_decade_monthly_mn$month <- rep(c(10:12,1:9), times=10)
recent_decade_mon_mn <- aggregate(ConcDay ~ month, data = recent_decade_monthly_mn, 'mean')
recent_decade_mon_sd <- aggregate(ConcDay ~ month, data = recent_decade_monthly_mn, 'sd')
recent_decade_mon_mn <- recent_decade_mon_mn[c(10:12,1:9),]
recent_decade_mon_sd <- recent_decade_mon_sd[c(10:12,1:9),]
mdat2 <- matrix(c(early_decade_mon_mn$ConcDay, recent_decade_mon_mn$ConcDay),
nrow=2,ncol = 12, byrow=TRUE,
dimnames = list(c("1990-2000", "2001-2011"),
c(format(seq(as.Date('1973-10-01'), as.Date('1974-09-01'), by='month'), '%b'))))
# Be sure to adjust the legend's first decade start and stop year correctly
mx <- max(c((early_decade_mon_mn$ConcDay + early_decade_mon_sd$ConcDay), (recent_decade_mon_mn$ConcDay + recent_decade_mon_sd$ConcDay)))
tiff("timing_shift_in_OP_conc_monthly_means.tif", height=800, width=900, res=130)
par(mar=c(3,5,2,1))
x <- barplot(mdat2, beside=TRUE, las=1, ylim=c(0,mx), col = c("lightblue", "mistyrose"))
abline(h=0)
arrows(x0=x[1,], y0=early_decade_mon_mn$ConcDay - early_decade_mon_sd$ConcDay, x1=x[1,], y1=early_decade_mon_mn$ConcDay + early_decade_mon_sd$ConcDay, angle=90, length=0.04, code=3)
arrows(x0=x[2,], y0=recent_decade_mon_mn$ConcDay - recent_decade_mon_sd$ConcDay, x1=x[2,], y1=recent_decade_mon_mn$ConcDay + recent_decade_mon_sd$ConcDay, angle=90, length=0.04, code=3)
mtext(side=2, expression(paste(OP,', mg ',L^-1,sep='')), line=3)
legend(x=25, y=0.9 * mx, c("1990-2000", "2001-2011"), pch=c(22,22), pt.cex=2, pt.bg=c("lightblue", "mistyrose"), bty='n', xpd=TRUE)
dev.off()
# Now attempting a Wilcox Test (aka Mann-Whitney-Wilcoxon Rank Sum test)
# ----------------------------------------------------------------------
early_jan <- subset(early_decade_monthly_mn, month==1)
recent_jan <- subset(recent_decade_monthly_mn, month==1)
UT5_OP_conc_jan_wilcox <- wilcox.test(recent_jan$ConcDay, early_jan$ConcDay, exact=TRUE, conf.int = TRUE, conf.level = 0.9)
early_feb <- subset(early_decade_monthly_mn, month==2)
recent_feb <- subset(recent_decade_monthly_mn, month==2)
UT5_OP_conc_feb_wilcox <- wilcox.test(recent_feb$ConcDay, early_feb$ConcDay, exact=TRUE, conf.int = TRUE, conf.level = 0.9)
early_mar <- subset(early_decade_monthly_mn, month==3)
recent_mar <- subset(recent_decade_monthly_mn, month==3)
UT5_OP_conc_mar_wilcox <- wilcox.test(recent_mar$ConcDay, early_mar$ConcDay, exact=TRUE, conf.int = TRUE, conf.level = 0.9)
early_apr <- subset(early_decade_monthly_mn, month==4)
recent_apr <- subset(recent_decade_monthly_mn, month==4)
UT5_OP_conc_apr_wilcox <- wilcox.test(recent_apr$ConcDay, early_apr$ConcDay, exact=TRUE, conf.int = TRUE, conf.level = 0.9)
early_may <- subset(early_decade_monthly_mn, month==5)
recent_may <- subset(recent_decade_monthly_mn, month==5)
UT5_OP_conc_may_wilcox <- wilcox.test(recent_may$ConcDay, early_may$ConcDay, exact=TRUE, conf.int = TRUE, conf.level = 0.9)
early_jun <- subset(early_decade_monthly_mn, month==6)
recent_jun <- subset(recent_decade_monthly_mn, month==6)
UT5_OP_conc_jun_wilcox <- wilcox.test(recent_jun$ConcDay, early_jun$ConcDay, exact=TRUE, conf.int = TRUE, conf.level = 0.9)
early_jul <- subset(early_decade_monthly_mn, month==7)
recent_jul <- subset(recent_decade_monthly_mn, month==7)
UT5_OP_conc_jul_wilcox <- wilcox.test(recent_jul$ConcDay, early_jul$ConcDay, exact=TRUE, conf.int = TRUE, conf.level = 0.9)
early_aug <- subset(early_decade_monthly_mn, month==8)
recent_aug <- subset(recent_decade_monthly_mn, month==8)
UT5_OP_conc_aug_wilcox <- wilcox.test(recent_aug$ConcDay, early_aug$ConcDay, exact=TRUE, conf.int = TRUE, conf.level = 0.9)
early_sep <- subset(early_decade_monthly_mn, month==9)
recent_sep <- subset(recent_decade_monthly_mn, month==9)
UT5_OP_conc_sep_wilcox <- wilcox.test(recent_sep$ConcDay, early_sep$ConcDay, exact=TRUE, conf.int = TRUE, conf.level = 0.9)
early_oct <- subset(early_decade_monthly_mn, month==10)
recent_oct <- subset(recent_decade_monthly_mn, month==10)
UT5_OP_conc_oct_wilcox <- wilcox.test(recent_oct$ConcDay, early_oct$ConcDay, exact=TRUE, conf.int = TRUE, conf.level = 0.9)
early_nov <- subset(early_decade_monthly_mn, month==11)
recent_nov <- subset(recent_decade_monthly_mn, month==11)
UT5_OP_conc_nov_wilcox <- wilcox.test(recent_nov$ConcDay, early_nov$ConcDay, exact=TRUE, conf.int = TRUE, conf.level = 0.9)
early_dec <- subset(early_decade_monthly_mn, month==12)
recent_dec <- subset(recent_decade_monthly_mn, month==12)
UT5_OP_conc_dec_wilcox <- wilcox.test(recent_dec$ConcDay, early_dec$ConcDay, exact=TRUE, conf.int = TRUE, conf.level = 0.9)
Conc_compare <- data.frame(chng_est=c(UT5_OP_conc_oct_wilcox$est,
UT5_OP_conc_nov_wilcox$est,
UT5_OP_conc_dec_wilcox$est,
UT5_OP_conc_jan_wilcox$est,
UT5_OP_conc_feb_wilcox$est,
UT5_OP_conc_mar_wilcox$est,
UT5_OP_conc_apr_wilcox$est,
UT5_OP_conc_may_wilcox$est,
UT5_OP_conc_jun_wilcox$est,
UT5_OP_conc_jul_wilcox$est,
UT5_OP_conc_aug_wilcox$est,
UT5_OP_conc_sep_wilcox$est),
low_conf=c(UT5_OP_conc_oct_wilcox$conf.int[1],
UT5_OP_conc_nov_wilcox$conf.int[1],
UT5_OP_conc_dec_wilcox$conf.int[1],
UT5_OP_conc_jan_wilcox$conf.int[1],
UT5_OP_conc_feb_wilcox$conf.int[1],
UT5_OP_conc_mar_wilcox$conf.int[1],
UT5_OP_conc_apr_wilcox$conf.int[1],
UT5_OP_conc_may_wilcox$conf.int[1],
UT5_OP_conc_jun_wilcox$conf.int[1],
UT5_OP_conc_jul_wilcox$conf.int[1],
UT5_OP_conc_aug_wilcox$conf.int[1],
UT5_OP_conc_sep_wilcox$conf.int[1]),
up_conf=c(UT5_OP_conc_oct_wilcox$conf.int[2],
UT5_OP_conc_nov_wilcox$conf.int[2],
UT5_OP_conc_dec_wilcox$conf.int[2],
UT5_OP_conc_jan_wilcox$conf.int[2],
UT5_OP_conc_feb_wilcox$conf.int[2],
UT5_OP_conc_mar_wilcox$conf.int[2],
UT5_OP_conc_apr_wilcox$conf.int[2],
UT5_OP_conc_may_wilcox$conf.int[2],
UT5_OP_conc_jun_wilcox$conf.int[2],
UT5_OP_conc_jul_wilcox$conf.int[2],
UT5_OP_conc_aug_wilcox$conf.int[2],
UT5_OP_conc_sep_wilcox$conf.int[2]))
write.table(Conc_compare, "UT5_OP_conc_wilcox.txt", quote=FALSE, row.names=FALSE)
rng <- max(abs(c(Conc_compare$up_conf, Conc_compare$low_conf)))
tiff("UT5_OP_conc_shift_wilcox_Vert_Bars.tif", height=600, width=800, res=130)
par(mar=c(4,5,0.5,0.5))
plot(seq(1:12), Conc_compare$chng_est, typ='h', lend=1, lwd=15, col='white', xaxt='n', xlim=c(1,13), ylim=c(-rng, rng), xlab="Month", ylab=expression(paste("Median Concentration Change, mg  ",L^-1,sep='')), las=1)
plotCI(seq(1:12), Conc_compare$chng_est, ui=Conc_compare$up_conf, li=Conc_compare$low_conf, pch=16, add=TRUE)
abline(h=0)
axis(side=1,at=seq(1,12,by=1), labels=format(c(seq(as.Date("2000-10-01"), as.Date("2000-12-01"), by="month"), seq(as.Date("2000-01-01"), as.Date("2000-09-01"), by="month")),'%b'), las=2)
legend('topright', c("Median difference", "90% Confidence Interval for the Median"), pch=c(16,NA), lwd=c(NA,1), pt.cex=c(1,NA), pt.bg=c('black',NA), bty='n', bg='white')
dev.off()
